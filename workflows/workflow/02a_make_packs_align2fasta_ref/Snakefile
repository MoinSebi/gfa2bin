import pandas as pd

wf_basedir = workflow.current_basedir

# TODO move to a common file for all modules
##### Helper functions #####
def get_fastq(wildcards):
    """Get fastq files of given sample."""
    print(wildcards)
    print(samples)
    fastqs = samples.loc[(wildcards.sample), ["fq1", "fq2"]].dropna()
    print(fastqs)
    if len(fastqs) == 2:
        return [fastqs.fq1, fastqs.fq2]
    return [fastqs.fq1]

#Load the samples
samples = pd.read_csv(config["samples"], sep=",",dtype=str).set_index("sample", drop=False)
print(samples.index)
# samples = samples.drop_duplicates()
# samples.index.names = ["sample_id"]


rule target:
    input:
        # pc_files=expand("results/02_packs/{reference_name}.{sample}.pc", reference_name=config["reference_name"], sample=samples.index),
        pack_files=expand("results/02_packs/{reference_name}.{sample}.pack", reference_name=config["reference_name"], sample=samples.index),


rule align_to_fasta_ref_with_bwa:
    params:
        threads=8
    conda:
        "../envs/main.yaml"
    input:
        validation_file="results/00_validate_inputs/sample_names_validation.txt",
        fasta_ref="results/01_fasta_ref/{reference_name}.all.fasta.gz",
        fastq=get_fastq
    output:
        bam_file=temp("results/02_packs/{reference_name}.{sample}.bam")
    shell:
        """
        bwa mem {input.fasta_ref} {input.fastq} -t {params.threads} | \
        samtools sort -@ 8 -o {output.bam_file} - 
        """

# Here use vg inject, but gfainject is also possible, vg inject did not always work?
# Check /tmp/global2/svorbrugg/tmp/1001g+data/align/run_pc/scripts/Snakefile for reference
rule inject_graph_with_bams:
#    params:
#        gfainject=config["gfainject"]
    priority: 10000
    conda:
        "../envs/main.yaml"
    input:
        #bam_files=expand("results/02_packs/{reference_name}.{sample}.bam", reference_name=config["reference_name"], sample=samples.index),
        bam_file="results/02_packs/{reference_name}.{sample}.bam",
        graph_file=config["graph"]
    output:
        # graph_with_bam=temp("results/02_packs/{reference_name}.{sample}.gaf") # gfainject
        graph_with_bam=temp("results/02_packs/{reference_name}.{sample}.gam")
    shell:
        """
        vg inject -x {input.graph_file} {input.bam_file} > {output.graph_with_bam}
        """

#{params.gfainject} \
#    --gfa {input.graph_file} \
#    --bam {input.bam_file} \
#    > {output.graph_with_bam} \


# Uses vg, gaf2pack as alternative, see above
rule create_pack_files:
    priority: 100000
    conda:
        "../envs/main.yaml"
    params:
        packing_tool=config["packing_tool"]
    input:
        gam_file="results/02_packs/{reference_name}.{sample}.gam",
        gfa=config["graph"]
    output:
        pack_file="results/02_packs/{reference_name}.{sample}.pc"
    shell:
        """
        vg pack -x {input.gfa} -g {input.gam_file} -d | \
        {params.packing_tool} compress --pack - --output {output.pack_file}
        """

#------------------------------------------------------------------------------------------------
# # Not checked yet
# rule index_graph: #check this rule, used later for gfa2bin -- > needed only if compressed pack is used
#     input:
#         gfa_file=config["graph"],
#     output:
#         indexed_graph="results/02_packs/{reference_name}.pi"
#     shell:
#         "packing index -i {input.gfa_file} -o {output.indexed_graph}"

# Flag: compress pack, keep pack?
# # Optional?
# rule: compress_pack:
#     input:
#         pack_file="results/02_packs/{reference_name}.{sample}.pack"
#     output:
#         compressed_pack_file="results/02_packs/{reference_name}.{sample}.pc"
#     shell:
#         "packing compress -p {input.pack_file} -o {output.compressed_pack_file}"

